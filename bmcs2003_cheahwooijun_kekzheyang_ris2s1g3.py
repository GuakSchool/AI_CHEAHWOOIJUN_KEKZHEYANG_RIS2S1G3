# -*- coding: utf-8 -*-
"""BMCS2003_CheahWooiJun_KekZheYang_RIS2S1G3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pBUvrB4i11diO3w937iN0FyfJXsBy0gx
"""

from google.colab import drive
drive.mount('/content/drive')

# Cell 1: Installations and imports
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import ast
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error

# Cell 2: Load data from Google Drive
def load_data_from_drive():
    movies_path = '/content/movies_metadata.csv'
    credits_path = '/content/credits.csv'
    ratings_path = '/content/ratings_small.csv'

    movies = pd.read_csv(movies_path)
    credits = pd.read_csv(credits_path)
    ratings = pd.read_csv(ratings_path)

    # Filter movies with more votes for faster processing
    movies = movies[movies['vote_count'] > 500]

 # Convert IDs
    movies['id'] = pd.to_numeric(movies['id'], errors='coerce')
    credits['id'] = pd.to_numeric(credits['id'], errors='coerce')
    ratings['movieId'] = pd.to_numeric(ratings['movieId'], errors='coerce')
    movies = movies.dropna(subset=['id'])
    credits = credits.dropna(subset=['id'])
    ratings = ratings.dropna(subset=['movieId'])
    movies['id'] = movies['id'].astype(int)
    credits['id'] = credits['id'].astype(int)
    ratings['movieId'] = ratings['movieId'].astype(int)

    # Merge movies + credits
    movies = movies.merge(credits, on='id', how='inner')

    # Clean features
    movies['overview'] = movies['overview'].fillna('')
    movies['tagline'] = movies['tagline'].fillna('')
    movies['description'] = movies['overview'] + " " + movies['tagline']

    movies = movies[['id', 'title', 'description', 'genres', 'cast', 'crew']]

    # Parsing helpers
    def parse_genres(obj):
        try: return [i['name'] for i in ast.literal_eval(obj)]
        except: return []
    def parse_cast(obj):
        try: return [i['name'] for i in ast.literal_eval(obj)[:3]]
        except: return []
    def parse_crew(obj):
        try: return [i['name'] for i in ast.literal_eval(obj) if i['job']=='Director']
        except: return []

    movies['genres'] = movies['genres'].apply(parse_genres)
    movies['cast'] = movies['cast'].apply(parse_cast)
    movies['crew'] = movies['crew'].apply(parse_crew)

    # Convert lists ‚Üí strings
    movies['genres'] = movies['genres'].apply(lambda x: " ".join(x))
    movies['cast'] = movies['cast'].apply(lambda x: " ".join(x))
    movies['crew'] = movies['crew'].apply(lambda x: " ".join(x))

    movies['final_features'] = (
        movies['description'] + ' ' +
        movies['genres'] + ' ' +
        movies['cast'] + ' ' +
        movies['crew']
    )
    return movies, ratings

# Cell 3: Create TF-IDF model
def create_tfidf_model(movies, pickle_path="/content/drive/MyDrive/tfidf_model.pkl"):
    # If pickle exists, load it
    try:
        with open(pickle_path, "rb") as f:
            tfidf, vectors = pickle.load(f)
        print("Loaded TF-IDF model from pickle")
    except:
        print("Creating new TF-IDF model...")
        tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
        vectors = tfidf.fit_transform(movies['final_features'])
        # Save to pickle
        with open(pickle_path, "wb") as f:
            pickle.dump((tfidf, vectors), f)
        print("TF-IDF model created and saved")
    return tfidf, vectors

# Cell 4: Prepare collaborative data
def prepare_collaborative_data(movies, ratings):
    movies_cf = movies[['id','title']].rename(columns={'id':'movieId'})
    ratings = ratings.merge(movies_cf, on="movieId", how="inner")

    user_mapping = {1: "Bob", 2: "Alice", 3: "Charlie", 4: "Diana", 5: "Eve"}
    ratings['user_name'] = ratings['userId'].replace(user_mapping)

    user_item_matrix = ratings.pivot_table(index='user_name', columns='title', values='rating').fillna(0)

    from sklearn.metrics.pairwise import cosine_similarity
    user_sim = cosine_similarity(user_item_matrix)
    user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)

    return ratings, user_item_matrix, user_sim_df

# Cell 5: Recommendation functions
# Content-based
def content_based_recommend(movie_title, movies, vectors, top_n=10):
    if movie_title not in movies['title'].values:
        return "‚ùå Movie not found", []
    idx = movies[movies['title']==movie_title].index[0]
    scores = linear_kernel(vectors[idx], vectors).flatten()
    indices = scores.argsort()[-(top_n+1):-1][::-1]
    return "Content-based recommendations", [(movies.iloc[i].title, float(scores[i])) for i in indices]

# Collaborative
def collaborative_recommend(user_name, user_item_matrix, user_sim_df, top_n=50):
    if user_name not in user_item_matrix.index:
        return {}
    sim_scores = user_sim_df[user_name].drop(user_name).sort_values(ascending=False)
    top_users = sim_scores.index[:5]
    neighbor_ratings = user_item_matrix.loc[top_users].mean(axis=0)
    watched = user_item_matrix.loc[user_name][user_item_matrix.loc[user_name]>0].index
    neighbor_ratings = neighbor_ratings.drop(watched, errors='ignore')
    top_recs = neighbor_ratings.sort_values(ascending=False).head(top_n)
    return {title: score for title, score in top_recs.items()}

# Hybrid
def hybrid_recommend(user_name, liked_movie, movies, vectors, user_item_matrix, user_sim_df, alpha=0.5, top_n=10):
    if not user_name or user_name.strip()=="" or user_name=="-":
        user_name = f"User_{random.randint(6,671)}"
    collab_scores = collaborative_recommend(user_name, user_item_matrix, user_sim_df, top_n=50)
    if liked_movie not in movies['title'].values:
        return user_name, [("‚ùå Movie not found", 0.0)]
    idx = movies.index[movies['title']==liked_movie][0]
    cs = linear_kernel(vectors[idx], vectors).flatten()
    content_scores = {movies.iloc[i].title: float(cs[i]) for i in cs.argsort()[-51:-1]}
    all_titles = set(collab_scores.keys()) | set(content_scores.keys())
    hybrid_scores = {t: alpha*content_scores.get(t,0)+ (1-alpha)*collab_scores.get(t,0) for t in all_titles}
    ranked = sorted(hybrid_scores.items(), key=lambda x:x[1], reverse=True)[:top_n]
    return user_name, [(t,float(s)) for t,s in ranked]

# ----- Evaluation Functions -----
def content_predict(user_id, movie_id, movies, ratings_aggregated, content_similarity):
    if movie_id not in movies['id'].values:
        return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings_aggregated[ratings_aggregated['userId'] == user_id]
    if user_ratings.empty:
        return None
    sim_scores = []
    for _, row in user_ratings.iterrows():
        if row['movieId'] in movies['id'].values:
            jdx = movies[movies['id'] == row['movieId']].index[0]
            sim_scores.append((row['rating'], sims[jdx]))
    if not sim_scores:
        return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

# Aggregate duplicate ratings by taking the mean before pivoting
# This is now done outside the function

def collab_predict(user_id, movie_id, ratings_matrix, user_sim_df):
    if movie_id not in ratings_matrix.columns:
        return None
    if user_id not in user_sim_df.index:
        return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore')
    top_users = sims.sort_values(ascending=False).head(5).index

    # Check if top_users is empty
    if top_users.empty:
        return None

    # Ensure movie_id is in the columns of ratings_matrix for top_users
    if movie_id not in ratings_matrix.columns:
        return None

    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]

    # Handle cases where weights might be all zeros
    if weights.sum() == 0:
        return None

    return np.dot(top_ratings, weights)/weights.sum()

def hybrid_predict(user_id, movie_id, movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df, alpha=0.5):
    cp = content_predict(user_id, movie_id, movies, ratings_aggregated, content_similarity)
    cf = collab_predict(user_id, movie_id, ratings_matrix, user_sim_df)
    if cp is None and cf is None:
        return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

def evaluate_model(predict_func, movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df, n_samples=300):
    # Ensure the sampled ratings are in the aggregated dataframe
    test = ratings_aggregated.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        # Pass necessary arguments to predict_func
        if predict_func.__name__ == 'content_predict':
            pred = predict_func(row['userId'], row['movieId'], movies, ratings_aggregated, content_similarity)
        elif predict_func.__name__ == 'collab_predict':
             pred = predict_func(row['userId'], row['movieId'], ratings_matrix, user_sim_df)
        elif predict_func.__name__ == 'hybrid_predict':
             pred = predict_func(row['userId'], row['movieId'], movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df)
        else:
            pred = predict_func(row['userId'], row['movieId']) # For other predict functions

        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds:
        return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

# ----- Run Evaluation -----
# This part will be moved to the next cell (Cell 7) to ensure data loading and TF-IDF creation are done first.

# Cell 7: Run evaluation and Demo recommendations

# Load data and create TF-IDF model
movies, ratings = load_data_from_drive()
tfidf, vectors = create_tfidf_model(movies)

# Prepare collaborative data
ratings_aggregated = ratings.groupby(['userId', 'movieId'])['rating'].mean().reset_index()
ratings_matrix = ratings_aggregated.pivot(index="userId", columns="movieId", values="rating").fillna(0)
user_sim = cosine_similarity(ratings_matrix)
user_sim_df_eval = pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index) # Renamed to avoid conflict with user_sim_df in hybrid_recommend
content_similarity = linear_kernel(vectors, vectors) # Calculate content similarity matrix

print("Running evaluation...")
mse_content, rmse_content = evaluate_model(content_predict, movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df_eval)
mse_collab, rmse_collab = evaluate_model(collab_predict, movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df_eval) # Removed movies, content_similarity as they are not used in collab_predict within evaluate_model
mse_hybrid, rmse_hybrid = evaluate_model(hybrid_predict, movies, ratings_aggregated, content_similarity, ratings_matrix, user_sim_df_eval)


results_df = pd.DataFrame({
    "System": ["Content-Based", "Collaborative", "Hybrid"],
    "MSE": [mse_content, mse_collab, mse_hybrid],
    "RMSE": [rmse_content, rmse_collab, rmse_hybrid]
})

print("üìä Evaluation Results:")
display(results_df)

# Cell 8: Visualization
plt.figure(figsize=(8,4))
sns.barplot(x="System", y="RMSE", data=results_df, palette="viridis")
plt.title("RMSE Comparison (Lower is Better)")
plt.show()

plt.figure(figsize=(8,4))
sns.barplot(x="System", y="MSE", data=results_df, palette="magma")
plt.title("MSE Comparison (Lower is Better)")
plt.show()

# Cell 9: Demo recommendations
def demo_recommendations(movies, vectors, user_item_matrix, user_sim_df):
    print("=== MOVIE RECOMMENDER SYSTEM DEMO ===")

    # Content-based recommendation demo
    print("\n1. Content-Based Recommendations:")
    movie_title = "The Dark Knight"  # Example movie
    if movie_title in movies['title'].values:
        method_name, recs = content_based_recommend(movie_title, movies, vectors, top_n=5)
        print(f"Top 5 content-based recommendations for '{movie_title}':")
        for i, (title, score) in enumerate(recs, 1):
            print(f"{i}. {title} (score: {score:.4f})")
    else:
        print(f"Movie '{movie_title}' not found in database")

    # Hybrid recommendation demo
    print("\n2. Hybrid Recommendations:")
    user_name = "Bob"
    movie_title = "The Dark Knight"
    if movie_title in movies['title'].values and user_name in user_item_matrix.index:
        user_display, recs = hybrid_recommend(user_name, movie_title, movies, vectors, user_item_matrix, user_sim_df, top_n=5)
        print(f"Top 5 hybrid recommendations for user '{user_display}' based on '{movie_title}':")
        for i, (title, score) in enumerate(recs, 1):
            print(f"{i}. {title} (score: {score:.4f})")
    else:
        print(f"Movie '{movie_title}' or user '{user_name}' not found")

# Prepare data for demo recommendations
ratings_demo, user_item_matrix_demo, user_sim_df_demo = prepare_collaborative_data(movies, ratings) # Use original ratings for demo

# Run the demo
demo_recommendations(movies, vectors, user_item_matrix_demo, user_sim_df_demo)